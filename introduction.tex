\section{Introduction}\label{sec:introduction}

A blockchain is a data structure where \emph{transactions} are kept inside blocks.
Blocks form a chain (a list), where each block $b$ \emph{points} to its previous block $p$
by referring, inside $b$, to the hash of $p$. Blocks must satisfy some consistency
rules, called \emph{consensus} rules; for instance, if $b$ refers to a previous bock hash
$h$ then a block $p$ having that hash must really exist in the chain; moreover, the timestamp
of $b$ must be larger than that of $p$; the size of $b$ must be smaller than a given threshold and so on.
The exact nature of the transactions is not relevant in this paper. In general, they are
requests to update the state of a global abstract machine; this state might be a ledger of
payments (as in the case of Bitcoin~\cite{Nakamoto08,Antonopoulos17}) or a sort of global RAM where data
structures can be allocated and subsequently modified (as in the case of Ethereum~\cite{AntonopoulosW18}).

The use of hashes as machine-independent
pointers allows blockchains to be implemented in a distributed way, in a network of peers.
Distributions is a desirable property because it entails that data is safely duplicated
in each peer and that there is no special peer that determines the history of the transactions.
However, each peer is free to expand the blockchain with new blocks, independently from the other
peers, so that, in general, there
are more blocks $b$ that refer to the same previous block $p$ and the blockchain is a tree rather than
a list of blocks. In order to make a single chain emerge as the \emph{best} chain, a notion of
chain quality is used: peers have incentives to append blocks to the chain with the highest quality.
This entails that a peer might replace its current best chain with another, even better chain,
if it receives the latter from other peers. This event is a \emph{history change}.

The above description of a distributed blockchain is still missing a key ingredient. Namely,
as presented above, each peer is free to generate new blocks at maximal speed, flooding the network
with new blocks, making difficult the emergence of a best chain and inducing frequent history changes.
This is not just an efficiency problem but also a security problem: history changes allow
\emph{double spending}, when the same money is moved in the ledger twice, once in the previous history
and once in the updated history. The actual genious of Nakamoto~\cite{Nakamoto08} has been to (largely)
solve these issues in a very elegant way, by exploiting an idea previously developed for combatting
email spam~\cite{DworkN92}. Namely, he added a consensus rule requiring that the (binary)
hash of each block $b$ must start with at least $\delta$ zeros, and connected the quality of a chain
to this hash. This means that the creation of a new block requires to rotate among
many possible values for a block field, called \emph{nonce}, until the hash of the block satisfies the
added consensus rule. This makes the creation of new blocks hard
(for larger $\delta$), makes it impossible to create blocks at arbitrary speed and creates a heavy
incentive to expanding the best chain, rather than creating alternative histories, since otherwise a peer
risks spending work (concretely, electricity) for the creation of blocks that will be discarded by the other peers.
The value $\delta$ is called \emph{difficulty} and is not a constant: it changes in accordance with
the current, total computational power of the network, in order to keep the block creation rate at a predetermined value.
The process of finding a good nonce, that induces an
acceptable block hash, is the \emph{proof of work} algorithm: it is a brute force algorithm, because of the non-correlation
property of hash functions. A peer that performs the proof of work algorithm is said to \emph{mine}
a new block and is consequently a block \emph{miner}. Miners get remunerated for their work whenever
they mine a new block before all other miners. Theoretically, everybody can install a miner peer,
anonymously, which makes the idea of Bitcoin very democratic.

The proof of work secures a blockchain network, reducing the risk of double spending,
but comes at the price of energy consumption: the electricity used by the Bitcoin network is said
to be comparable to that of a medium-sized country; moreover, mining is not egalitarian, because
it is worthwhile only in countries where electricity is cheap; furthermore, the proof of work algorithm
is more efficient in dedicated, relatively expensive hardware (such as ASICs),
which deviates much from the idea of a democratically open network.

In order to overcome the issue with energy consumption, the recent trend in blockchain is to
replace the proof of work with a proof of stake. This comes in many different flavors, but
the shared idea is that mining is limited to a (static or dynamic, exclusive or delegatable)
set of peers, that commit
some cryptocurrency (a \emph{stake}) to gain the right of mining
in turn, or according to some alternation protocol. In general, these can be seen
as Byzantine consensus algorithms, as the one pioneering by
Tendermint (\url{https://github.com/tendermint/tendermint/wiki}).
Proof of stake is often criticized for being more centralized and less democratic than proof of work
(\emph{rich becomes richer}).
Moreover, it suffers from what we call the \emph{start-up issue}: as long as the cryptocurrency
of a newborn blockchain has still no value, it is difficult to convince miners to work and
be updated, since there is no incentive in doing so, initially. Starting and maintaining
a newborn blockchain becomes a difficult social and organizational problem. Finally, peers of
a proof of stake blockchain get punished (\emph{slashed}) if they are misbehaving or offline.
This is problematic if, for instance, a peer is offline but has no fault for that: it might be
because of a network connectivity issue or a black-out.

Among the alternatives to proof of work and proof of stake, we focus here on proof of space.
In a proof of space blockchain, peers have the right to mine new blocks (and be renumerated for that) if they dedicate
a large chunk of disk memory for mining. The energy consumption of proof of space is almost zero
and no dedicated hardware can be used for mining, currently. Therefore, mining becomes cheap and
more democratic than with a proof of work.
The theoretical background of proof of space has been developed, independently,
in the two seminal papers~\cite{AtenieseBFG14} and~\cite{DziembowskiFKP15},
that feature similarities but also significant differences. Both are based
on directed acyclic graphs (DAGs) of high pebbling complexity.
Pebbling, here, is a directed decoration of the nodes of the DAG with hashes, as in
a Merkle tree.
A prover must keep such a (big) DAG and its pebbling on disk, in order to answer, efficiently,
\emph{challenges} proposed by a verifier, with compact proofs that should convince the verifier that
the prover is actually keeping the DAG on disk. These proofs are used for mining new blocks,
instead of the nonce used in the proof of work. A notion of quality is defined for
the proofs, in such a way that the probability of deriving a proof of high quality increases
with the size of the DAG, which is an incentive to dedicating more space for mining.
While~\cite{DziembowskiFKP15} requires space to remain allocated between challenges,
and is consequently called a proof of \emph{persistent} space, \cite{AtenieseBFG14} requires
to allocate space only when anwering challenges and is consequently called
a proof of \emph{transient} space (or a proof of secure erasure, as~\cite{DziembowskiFKP15} calls it).
Both solutions have an initialization phase when the verifier performs a deeper challenge
of the prover and stores the resulting proof in blockchain.

%Cite~\cite{DziembowskiFKP15}. This seems to be the first description of proofs of space.
%Their algorithm is based on graph pebbling, where a vertex can be pebbled only if the
%its in-going vertices have been pebbled as well. This way they prove a lower bound on the
%complexity of their algorithm. They prove that that lower bound is valid also if a prover
%wants to use its CPU. They prove that the size of the space used by their algorithm
%is a lower bound to the execution cost of the algorithm if no space is reserved.
%Therefore, using proofs of work in a network of proofs of space nodes would
%be computationally too expensive.
%This is sometimes called proof of persistent space.
%There is an initialization protocol for each new prover, that is missing in Burstcoin.

%Cite~\cite{AtenieseBFG14}. Based on DAGs with high pebbling complexity. There are clear similarities
%with~\cite{DziembowskiFKP15}. They actually cite and compare with each other.
%According to~\cite{DziembowskiFKP15}, this article defines a proof of secure erasure,
%that however they call a proof of space. According to~\cite{DziembowskiFKP15},
%their proof of secure erasure
%implies a proof of space but not the other way round. There does not seem to exist
%any implementation. The issue with the size of the proofs would be identical to that
%of~\cite{DziembowskiFKP15}, because of the use of pebbling graphs.
%This is sometimes called proof of transient space: the puzzle function requires lot of
%memory space to compute, but after computation that space con be freed.

Cite~\cite{TangZDWLG0L19}. They tackle the problem of miners using the same stored data
for many chains. This is problematic for newborn chains, since they might get an attack
from miners (or coalition of miners) that already use a very big data file for mining other,
mature chains (\emph{newborn attack}). They present a solution over the SpaceMint protocol.
The idea is that the disk space of a miner can be split for mining on many chains
simultaneously, but there is an incentive at allocating a space, for each chain, proportional
to the market value of the chain.

Cite~\cite{RenD16}. It uses stacked expander graphs, to get simpler, more efficient and
provably space-hard solutions, than~\cite{AtenieseBFG14} and~\cite{DziembowskiFKP15}.
It works for both proof of transient space and proof of persistent space.
It performs a nice comparison of previous proofs of space
and related techniques (memory-hard functions, proof of secure erasure, provable data possession,
proof of retrievability).

Proof of retrievability~\cite{JuelsK07}: a large file
is sent from the verifier to the prover and the verifier
check, repeatedly, if the prover keeps that file in storage. It requires to transfer the file
at the beginning, for each new prover (miner).

Cite~\cite{ParkKFGAP18}. SpaceMint, previously Spacecoin. Consideration: PoW requires power
to be allocated if mining is worthwhile. PoS allows one to allocate unused space even if its
cost is higher than mining, since in any case it would remain unused. More egalitarian:
general-purpose hardware instead of ASIC. The use of a key for the miners makes it
impossible to build mining pools, which is said to be good, citing~\cite{MillerKKS15}.
They say PoS is more difficult to adapt to blockchain because the protocol is a bit
more complicated than PoW. It lists some problems of PoS: mining multiple chains simultaneously
(since they are cheap), creating more blocks with the same proof and then choose the most
favorable (block grinding). Nothing-at-stake problems. Quality-function to determine the winner, proportional
to the allocated space. How to fight block grinding: make the proof unique, based
on who won the previous round, use
two chains, for proofs and for transactions, the proofs depends on previous proofs only.
How to fight mining on multiple chains: previous blocks affect future blocks only in a limited way.
They provide a game-theoretic model showing that the system is a Nash equilibrium.
It cites proof of storage/retrievability: the verifier must send and keep a big file.
Some link with Permacoin, which is however still a PoW system with ethical data.
It cites Burstcoin (now Signum) and its time/memory tradeoff:
``a miner doing a little extra computation can mine at the same
rate as an honest miner, while using just a small fraction (e.g., 10\%) of the space.''
It talks about a problem with miners hashing 8 million blocks, that does not seem to exist
anymore, but better check what they mean.
It cites the Chia Network (proof of space and time), \url{https://www.chia.net/}.
It calls it proof of sequential work on top of proof of space.
It says that it is based on completely different theoretical work, that is~\cite{AbusalahACKPR17}.
Consideration: their mining uses special protocol transactions
(payments, space commitments, penalties) while Mokamint is completey transaction agnostic.
Arrival of new miners and penalties for miners are kept in blockchain!
To avoid mining for different chains, the next challenge is derived from the hash of a block
(from the proof chain) deep in the past. If two children blocks are created by the same miner,
a penalty transaction is generated. The transaction includes the two blocks (it is huge!)
that are consequently signed, which guarantees that it can be verified by nodes that might
only have one history in the database.
The same challenge is used for a few consecutive blocks, to fight challenge-grinding attacks.
The size of their proofs (node pebbling) reaches 3 megabytes. This prove is stored in blockchain
for the initialization of each new miner (which might be expensive) and cheaper proofs
(100K, thanks to some ``likely sound'' optimations) are reported in each mined block.
Mokamint's deadline have constant (small size).
Code of Spacemint: \url{https://github.com/kwonalbert/spacemint}. Just a very limited prototype of a
proofs of space algorithm. Not maintained in the last nine years.

Cite~\cite{AbusalahACKPR17}. It is the theoretical base of the Chia network.
They assert that pebbling-based approaches have two main issues: the size of the proof to include in each block
(megabytes) and the initialization phase for each prover joining a verifier. That is, crypto must be spent even before
starting mining (the prover is the miner in this context) while Bitcoin allows one
to start mining and collect crypto on the way.
They solve these issues (the same is solved in Burstcoin as well).
They propose a proof of space and time based on challenges about the inversion of a random function,
overcoming the well-known issue of time-memory trade-offs.
As concisely stated in~\cite{ParkKFGAP18}, the better the quality of the proof of space, the faster the block can
be \emph{finalized} by a proof of sequential work, and this
proof tuple then can be used to create a block.

Cite~\cite{Reyzin23}. It tackles the question: how much does it cost to store only a part of the file?
When storing less than all of the file, it should be difficult for the prover to recover the
missing portions of the file when answering queries from the verifier. They define some thresholds
on the portion kept for the file and on the consequent complexity degradation. Ideally, such thresholds
should be close to 0, meaning that almost all file must be kept in memory for having no complexity
explosion. They show that existing solutions have bad constants or can be considered as impractical.
They say that the initialization protocol of the DAGs prevents most cheating (incomplete calculations).
The missing pebbles (red nodes) must be calculated later during the execution protocol.
They provide lower bounds on the cosntants of the initialization protocol so that
the resulting partial pebbling has thresholds close to 0.
This article tackles a problem that actually affected Burstcoin (its time/memory trade-offs,
theoretically now solved in Burstcoin). However, proofs in this article donot apply to Burstcoin
because it is not based on pebbling graphs.

Cite~\cite{DworkN92}. The origin of proof of work. Mail senders must compute some
work to have their email accepted by the recipient. This work includes
the address of the recipeint and the date of sending, in order to avoid
work recycling. Typically, it consists in adding extra data at the end of the email
to that its hash is smaller than a predefined constant.

Burstcoin, now Signum: \url{https://wiki.signum.network/}. Rebranded from Burstcoin.
They call it proof of capacity but it's just proof of space.
There is a very raw description of the mining algorithm:
\url{https://wiki.signum.network/signum-plotting-technical-information/index.htm}.
It allows smart contracts in ``Java'', in a language called SmartJ. Examples
can be found at \url{https://github.com/signum-network/signum-smartj}.
While Hotmoka abstracts away all blockchain details, SmartJ requires programmers to
manually deal with them.
