\section{Prolog Structure, Protection against Attacks}\label{sec:prolog_structure_attacks}
%
This section proposes an extension to the framework in~\cite{SignumPlotting} and
discusses potential attacks to the algorithm.

The peers of Def.~\ref{def:blockchain_network} have two functions: to find new deadlines and to
package new blocks with such deadlines. In practice, two machines perform each of them:
one (the actual miner) finds deadlines by using plots: it must have a large disk space; the other (the actual peer)
receives deadlines, packages and whispers new blocks: it must have a good network connection.
Such machines will work for a blockchain network with a given chain identifier~\cite{Antonopoulos17}.
Therefore, we propose to use, as prologs, the byte representation of the following structure:
\[
\langle\text{chain identifier},\text{public key of the peer},\text{public key of the miner}\rangle
\]
(in~\cite{SignumPlotting}, prologs are just the public key of the miner).
Moreover, we add two new consensus rules to Def.~\ref{def:blockchain}. Informally, one requires
that the chain identifier in $b.\trunk.\delta$ is that of the blockchain; and the other requires that
the public key of the peer inside $b.\trunk.\delta$ matches the signature of the block $b$. This has many advantages:
%
\begin{itemize}
\item the public keys of peer and miner can be used to remunerate them for their contribution,
  in an application-specific way;
\item the creator of a plot must specify the public key of the peer: hence that plot
  can only be used to create deadlines for that given peer and miners become dedicated to that given
  peer, instead of working, with the same plot, for many peers. This creates a sort of miner
  fidelization and allows peers to compete by offering different remuneration schemes to miners;
\item the creator of a plot must specify the chain identifier of the blockchain.
  Therefore, it becomes impossible to use the same plot for mining two
  blockchain networks at the same time. This protects against newborn attacks.
\end{itemize}

In~\cite{ParkKFGAP18}, one criticism to Burstcoin was that the validation of a deadline
(Def.~\ref{def:deadline_validity}) requires to run
Alg.~\ref{alg:nonce_construction}, that in turn
requires hashing $8\cdot 10^6\cdot 32=256000000$ bytes.
It must be stated that
such hashing can actually be computed in a few milliseconds nowadays,
for a minimal energy cost. Moreover, that time is largely dominated
by the time for verifying the transactions in a block, in particular
for a blockchain, such as Signum, that allows smart contracts.
Therefore, the extra time for verifying the deadlines does not seem like a problem to us.
In any case, step~\ref{step:nonce_construction:first_hash} of
Alg.~\ref{alg:nonce_construction} currently uses a threshold $\kappa$,
that was possibly missing when~\cite{ParkKFGAP18} was written.
Considering that threshold and assuming the specific values and hashing
used in~\cite{SignumPlotting} (see rightmost column of Tab.~\ref{tab:notations}),
step~\ref{step:nonce_construction:first_hash}
hashes at most $\kappa$ bytes and is iterated $2\cdot\numberofscoops$ times, that is,
it hashes at most $33554432$ bytes.
Step~\ref{step:nonce_construction:final_hash} hashes $32\cdot 2\cdot 4096$ bytes
plus the size of the $\seed$, which is around $200$ bytes.
That is, it hashes $262344$ bytes. In total, Alg.~\ref{alg:nonce_construction}
hashes $33816776$ bytes, which is around $8$ times less than what reported
in~\cite{ParkKFGAP18}.

In~\cite{ParkPAFG15}, page~28, a potential block grinding attack was hinted for Burstcoin,
since, in~\cite{SignumPlotting}, the next challenge of a previous block used its undefined
\emph{previous block generator}:
``this seems possible to be grinded, by trying
different sets of transactions to include in a block''~\cite{ParkPAFG15}.
As discussed just after our Def.~\ref{def:next_challenge_from_trunk}, that notion is
just the prolog $\trunk.\delta.\pi$ of the deadline of the trunk in the previous block.
Consequently, it cannot be grinded: Signum is protected against block grinding attacks.
But we sympathize with~\cite{ParkPAFG15}: without a formalization,
it was impossible to exclude that attack.

It is also interesting to observe that Signum has partial protection
against challenge grinding attacks.
The challenge for the a block is actually uniquely determined by the trunk in its
previous block
(consensus rule~\ref{prop:consensus:answer} of Def.~\ref{def:blockchain}
and Def.~\ref{def:next_challenge_from_block}) but a peer
might select suboptimal deadlines at step~\ref{step:block_mining:next_deadline}
of Alg.~\ref{alg:block_mining} (that is, not the minimal one of Def.~\ref{def:deadline_from_plot}),
hoping that such a sacrifice will generate subsequent challenges for which the peer
can find very good deadlines.
%Therefore, in Signum, such an attack should be called \emph{deadline grinding}.
But that attack does not pay off, since the choice of suboptimal deadlines does not
affect the sequence of challenges, as shown below.
%
\begin{proposition}\label{prop:no_challenge_grinding}
  Let $B$ be a blockchain, $\plot\in\Plots$, $b_0,\ldots,b_n$ and
  $b_0',\ldots,b_n'$ be two sequences of blocks in $B$, rooted at the same
  $b_0=b_0'$, mined by using $\plot$ only
  (possibly with suboptimal choices of the deadlines), that is,
  %
  \begin{align*}
    b_i.\trunk.\delta&=\delta(\nonce_i,\plot.\pi,\challenge_\mynext(b_{i-1}))\\
    b'_i.\trunk.\delta&=\delta(\nonce'_i,\plot.\pi,\challenge_\mynext(b'_{i-1}))
  \end{align*}
  %
  for suitable $\nonce_i,\nonce_i'\in\plot.\nonces$, for every $1\le i\le n$. Then
  \[
  \challenge_\mynext(b_j)=\challenge_\mynext(b'_j)
  \]
  for every $0\le j\le n$.
\end{proposition}
%
Intuitively, the sequence of challenges depends only on
the sequence of prologs used for mining, that is always the same by using a given plot.
Therefore, a challenge grinding attack in Signum
would require to use many plots, with different keys, all in control of the peer,
and grind among the plots. However, the number of plots is limited by the space
allocated to the algorithm and the same set of plots
would be used at each mining step, since they are to expensive to compute
on the fly during grinding. This highly
limits the benefits of grinding. For additional protection, it is always possible to use
one of the techniques presented in~\cite{ParkKFGAP18} (see Sec.~\ref{sec:related_work}).

Signum does not seem to have any protection against mining on different chains instead.
The only possibility here seems to use the penalty transactions used in~\cite{ParkKFGAP18}
and challenges that
are not built from the previous block but from a predecessor block deeper in the chain
(see Sec.~\ref{sec:related_work}).

The original definition of Burstcoin was shown to have a time/memory tradeoff~\cite{ParkKFGAP18}:
it was possible to store $\finalhash$ only instead of each full nonce
(see step.~\ref{step:nonce_construction:final_hash} of Alg.~\ref{alg:nonce_construction}) and
reconstruct (some) scoops on demand. The resulting (mining power)/(space used) ratio was proportionally higher
than by storing the full nonces,
``at the price of having to compute a modest number of extra hashes''~\cite{ParkKFGAP18}.
We agree with the attack but not with the \emph{modest number} part: the discussion in Appendix~B
of~\cite{ParkKFGAP18} confuses plots with nonces and does not recognize that that modest number
must be computed for all nonces in the plot, which are easily too many, considering the
cost of the shabal256 hashing algorithm (Tab.~\ref{tab:notations}). In any case, the developers
of Signum have modified Alg.~\ref{alg:nonce_construction} with the addition of
step~\ref{step:nonce_construction:swap}, in order to cope with this time/memory tradeoff.
That extra step requires one to compute all $h_i$ in order to compute the scoops.
Therefore, this specific time/memory tradeoff does not occur anymore. Of course, proving
that the addition of step~\ref{step:nonce_construction:swap} is enough to ban all
time/memory tradeoffs remains an open question,
a daunting task that goes well beyond the scope of this paper.

